{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 634798\n"
     ]
    }
   ],
   "source": [
    "path = 'RNU_random.txt'\n",
    "text = open(path).read().lower()\n",
    "text = text.strip('\\n')\n",
    "test = text[:20000]\n",
    "text = text[20000:]\n",
    "print('length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunkstring(string, length):\n",
    "    return [string[0+i:length+i] for i in range(0, len(string), length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk_len = 2\n",
    "chunk = chunkstring(text,chunk_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '0a', '0b', '0c', '0d', '0e', '0f', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1a', '1b', '1c', '1d', '1e', '1f', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2a', '2b', '2c', '2d', '2e', '2f', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '3a', '3b', '3c', '3d', '3e', '3f', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '4a', '4b', '4c', '4d', '4e', '4f', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '5a', '5b', '5c', '5d', '5e', '5f', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '6a', '6b', '6c', '6d', '6e', '6f', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '7a', '7b', '7c', '7d', '7e', '7f', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '8a', '8b', '8c', '8d', '8e', '8f', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '9a', '9b', '9c', '9d', '9e', '9f', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9', 'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'ca', 'cb', 'cc', 'cd', 'ce', 'cf', 'd0', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'da', 'db', 'dc', 'dd', 'de', 'df', 'e0', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8', 'e9', 'ea', 'eb', 'ec', 'ed', 'ee', 'ef', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'fa', 'fb', 'fc', 'fd', 'fe', 'ff']\n",
      "total number of hex: 256\n"
     ]
    }
   ],
   "source": [
    "hexs = sorted(list(set(chunk)))\n",
    "print(hexs)\n",
    "\n",
    "print('total number of hex:', len(hexs))\n",
    "\n",
    "hex_indices = dict((c, i) for i, c in enumerate(hexs))\n",
    "indices_hex = dict((i, c) for i, c in enumerate(hexs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 105796\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 11\n",
    "step = 3\n",
    "sequences = []\n",
    "next_hex = []\n",
    "for i in range(0, len(chunk) - maxlen, step):\n",
    "    sequences.append(text[i*chunk_len: (i + maxlen)*chunk_len])\n",
    "    next_hex.append(text[(i + maxlen)*chunk_len:(i + maxlen + 1)*chunk_len])\n",
    "print('number of sequences:', len(sequences))\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sequences), maxlen, len(hexs)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(hexs)), dtype=np.bool)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    #print ('sentence', sentence)\n",
    "    for t, char in enumerate(chunkstring(sequence,chunk_len)):        \n",
    "        X[i, t, hex_indices[char]] = 1\n",
    "    y[i, hex_indices[next_hex[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=False,input_shape=(maxlen, len(hexs))))\n",
    "model.add(Dense(len(hexs)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):    \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING:theano.tensor.blas:We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Epoch 1/1\n",
      "105796/105796 [==============================] - 244s - loss: 5.5531 - acc: 0.0040   \n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for iteration in range(1, 2):    \n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 20000\n"
     ]
    }
   ],
   "source": [
    "# testing with test dataset\n",
    "text = test\n",
    "print('corpus length:', len(text))\n",
    "chunk = chunkstring(text,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 9989\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step = 1\n",
    "sequences = []\n",
    "next_hex = []\n",
    "for i in range(0, len(chunk) - maxlen, step):\n",
    "    sequences.append(text[i*2: (i + maxlen)*2])\n",
    "    next_hex.append(text[(i + maxlen)*2:(i + maxlen + 1)*2])\n",
    "print('sequences:', len(sequences))\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sequences), maxlen, len(hexs)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(hexs)), dtype=np.bool)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    #print ('sequences', sequences)\n",
    "    for t, char in enumerate(chunkstring(sequence,2)):        \n",
    "        X[i, t, hex_indices[char]] = 1\n",
    "    y[i, hex_indices[next_hex[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 0\n",
      "Processed 500 1\n",
      "Processed 1000 1\n",
      "Processed 1500 4\n",
      "Processed 2000 7\n",
      "Processed 2500 8\n",
      "Processed 3000 11\n",
      "Processed 3500 13\n",
      "Processed 4000 13\n",
      "Processed 4500 14\n",
      "Processed 5000 16\n",
      "Processed 5500 19\n",
      "Processed 6000 19\n",
      "Processed 6500 21\n",
      "Processed 7000 22\n",
      "Processed 7500 22\n",
      "Processed 8000 25\n",
      "Processed 8500 28\n",
      "Processed 9000 29\n",
      "Processed 9500 32\n",
      "32 0.32%\n"
     ]
    }
   ],
   "source": [
    "n_true = 0\n",
    "diversity = 1\n",
    "for i,x in enumerate(X):\n",
    "    if i % 500 == 0:\n",
    "        print (\"Processed %d %d\" % (i,n_true))\n",
    "    x = x.reshape(1,maxlen,-1)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "\n",
    "    next_index = sample(preds, diversity)\n",
    "    #print (next_index)\n",
    "    next_hex = indices_hex[next_index]   \n",
    "    if next_hex == indices_hex[np.argmax(y[i])]:\n",
    "        n_true += 1\n",
    "print (\"%d %.2f%%\" % (n_true,100.0*n_true/len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
