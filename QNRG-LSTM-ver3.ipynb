{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, MaxPooling1D, Flatten\n",
    "from keras.layers import LSTM,Convolution1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = './QRNG Raw/170517/170517_RW_E--ch0.dat'\n",
    "\n",
    "data = np.fromfile(filename, dtype='>i2')\n",
    "data = data[2:]    \n",
    "data = data >> 3\n",
    "    \n",
    "mu, sigma = np.mean(data), np.std(data)\n",
    "print mu, sigma\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(data, 1024, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = mlab.normpdf( bins, mu, sigma)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=1)\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(r'$\\mathrm{Histogram\\ of\\ QNRG\\ raw\\ data:}\\ $')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "text = data[:5000000]\n",
    "\n",
    "# Test sets\n",
    "test1 = data[5000000:6000000]\n",
    "test2 = data[6000000:7000000]\n",
    "test3 = data[7000000:8000000]\n",
    "test4 = data[8000000:9000000]\n",
    "test5 = data[9000000:]\n",
    "\n",
    "text = list(text)\n",
    "test1 = list(test1)\n",
    "test2 = list(test2)\n",
    "test3 = list(test3)\n",
    "test4 = list(test4)\n",
    "test5 = list(test5)\n",
    "\n",
    "# Treating each number as a \"word\"\n",
    "text = map(str,text)\n",
    "test1 = map(str,test1)\n",
    "test2 = map(str,test2)\n",
    "test3 = map(str,test3)\n",
    "test4 = map(str,test4)\n",
    "test5 = map(str,test5)\n",
    "\n",
    "print len(text), len(test1), len(test5)\n",
    "print text[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treating each number as a \"word\". Creating a dictionary.\n",
    "data = data.astype(np.str)\n",
    "chars = sorted(list(set(data)))\n",
    "print(chars)\n",
    "del data\n",
    "print('Total words:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Length of input. Treating each input that consists of 100 \"words\" as a \"sentence\".\n",
    "maxlen = 100\n",
    "# Distance between 2 consecutive \"sentences\"\n",
    "step = 13\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: (i + maxlen)])\n",
    "    next_chars.append(text[(i + maxlen)])\n",
    "print('Number of sentences:', len(sentences))\n",
    "\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):    \n",
    "    for t, char in enumerate(sentence):        \n",
    "        X[i, t, char_indices[char]] = 1    \n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Done vectorization!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(filters=64, kernel_size=9, padding='same', activation='relu', input_shape=(maxlen, len(chars))))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Convolution1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "monitoring = ModelCheckpoint('weights_E1_ch0_ver5.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, nb_epoch=50, batch_size=128, validation_split=0.2, verbose=1, callbacks=[early_stopping,monitoring])\n",
    "model.load_weights('weights_E1_ch0_ver5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tests = [test1,test2,test3,test4,test5]\n",
    "del test1\n",
    "del test2\n",
    "del test3\n",
    "del test4\n",
    "del test5\n",
    "\n",
    "for test in tests:\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    maxlen = 100\n",
    "    step = 1\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(test) - maxlen, step):\n",
    "        sentences.append(test[i: (i + maxlen)])\n",
    "        next_chars.append(test[(i + maxlen)])\n",
    "    \n",
    "    Xt = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    yt = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        \n",
    "        for t, char in enumerate(sentence):        \n",
    "            Xt[i, t, char_indices[char]] = 1       \n",
    "        yt[i, char_indices[next_chars[i]]] = 1\n",
    "    n_true = 0\n",
    "    diversity = 1\n",
    "    \n",
    "    batch_size = 1000\n",
    "    nb_batch = Xt.shape[0]/batch_size\n",
    "    \n",
    "    for i in range(nb_batch):\n",
    "        if i % 100 == 0:\n",
    "            print (\"Processed %d, %d\" % (i*batch_size,n_true))\n",
    "        x = Xt[i*batch_size:(i+1)*batch_size]\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        pred_next_indexes = list(np.argmax(preds,axis=1))\n",
    "        pred_next_chars = [indices_char[next_index] for next_index in pred_next_indexes]        \n",
    "        y_pred += pred_next_chars\n",
    "        \n",
    "        true_next_indexes = list(np.argmax(yt[i*batch_size:(i+1)*batch_size],axis=1))\n",
    "        true_next_chars = [indices_char[next_index] for next_index in true_next_indexes]\n",
    "        y_true += true_next_chars\n",
    "        \n",
    "        n_true += np.sum(np.array(pred_next_chars)==np.array(true_next_chars))\n",
    "        \n",
    "    y_true = map(int,y_true)\n",
    "    y_pred = map(int,y_pred)\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    mse = np.mean(np.square(y_true-y_pred))\n",
    "    print ('mse',mse)\n",
    "    print (\"%d_%d_%.5f\" % (n_true,yt.shape[0],(float(n_true)/yt.shape[0])))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
